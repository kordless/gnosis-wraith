import os
import datetime
import logging
import aiofiles
import markdown
import json
from typing import List, Dict, Any

# Get logger from config
logger = logging.getLogger("gnosis_wraith")
REPORTS_DIR = os.environ.get('GNOSIS_WRAITH_REPORTS_DIR', os.path.join(os.path.expanduser("~"), ".gnosis-wraith/reports"))

def generate_markdown_report(title: str, crawl_results: List[Dict[str, Any]]) -> str:
    """Generate a markdown report from crawl results, including LLM summaries if available."""
    # Add logging for debugging
    logger.info(f"Generating markdown report with title: {title}")
    logger.info(f"Crawl results type: {type(crawl_results)}, length: {len(crawl_results)}")
    
    # Validate crawl_results
    if not isinstance(crawl_results, list):
        logger.error(f"crawl_results is not a list, but {type(crawl_results)}")
        crawl_results = [crawl_results] if crawl_results is not None else []
    
    # Log the first result for debugging
    if crawl_results:
        logger.info(f"First result type: {type(crawl_results[0])}")
        if isinstance(crawl_results[0], dict):
            logger.info(f"First result keys: {list(crawl_results[0].keys())}")
        else:
            logger.error(f"First result is not a dictionary but {type(crawl_results[0])}")
    
    md = f"# {title}\n\n"
    md += f"*Generated on {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n\n"
    
    # Add executive summary if available in results
    has_llm_summary = False
    for result in crawl_results:
        if isinstance(result, dict) and 'llm_summary' in result:
            has_llm_summary = True
            break
    
    if has_llm_summary:
        md += f"## Executive Summary\n\n"
        md += f"*This summary was generated by AI based on the collected content*\n\n"
        
        # Try to find an overall summary if one was generated
        overall_summary = None
        for result in crawl_results:
            if isinstance(result, dict) and 'overall_summary' in result:
                overall_summary = result.get('overall_summary')
                break
                
        if overall_summary:
            md += f"{overall_summary}\n\n"
        else:
            # Create a simple summary listing the pages analyzed
            md += f"This report contains analysis of {len(crawl_results)} URLs:\n\n"
            for result in crawl_results:
                if isinstance(result, dict) and 'error' not in result:
                    # Check if this is an uploaded file or URL
                    if 'original_filename' in result:
                        url_value = f"Local File: {result.get('original_filename', 'Unknown File')}"
                    else:
                        url_value = result.get('url', 'Unknown URL')
                    
                    # Ensure url_value is a string
                    if not isinstance(url_value, str):
                        url_value = str(url_value)
                    
                    # Use original filename as title if available
                    title_value = result.get('original_filename', result.get('title', 'Untitled'))
                    md += f"- {title_value}: {url_value}\n"
            md += "\n"
        
        md += "---\n\n"
    
    for i, result in enumerate(crawl_results, 1):
        # Skip if result is not a dictionary
        if not isinstance(result, dict):
            logger.error(f"Result at index {i-1} is not a dictionary but {type(result)}")
            continue
            
        # Use original filename as title if available
        title_value = result.get('original_filename', result.get('title', 'Untitled'))
        md += f"## {i}. {title_value}\n\n"
        
        # Check if this is an uploaded file or URL
        if 'original_filename' in result:
            file_value = result.get('original_filename', 'Unknown File')
            md += f"**File**: {file_value}\n\n"
        else:
            # Ensure URL is a string
            url_value = result.get('url', 'Unknown URL')
            if not isinstance(url_value, str):
                url_value = str(url_value)
            md += f"**URL**: {url_value}\n\n"
        
        # Add JavaScript setting information if available
        if 'javascript_enabled' in result:
            js_enabled = result.get('javascript_enabled', False)
            md += f"**JavaScript**: {'Enabled' if js_enabled else 'Disabled'}\n\n"
        
        if 'error' in result:
            error_value = result.get('error', 'Unknown error')
            if not isinstance(error_value, str):
                error_value = str(error_value)
            md += f"**Error**: {error_value}\n\n"
        else:
            # Add screenshot as image - use relative path
            if 'screenshot' in result:
                screenshot_value = result.get('screenshot')
                if not isinstance(screenshot_value, str):
                    logger.error(f"Screenshot value is not a string but {type(screenshot_value)}")
                    screenshot_value = str(screenshot_value)
                
                logger.info(f"Adding screenshot to report: {screenshot_value}")
                try:
                    # Get original filename from URL or path
                    original_filename = None
                    
                    # Try to get from metadata first if available
                    if 'original_filename' in result:
                        original_filename = result.get('original_filename')
                        if not isinstance(original_filename, str):
                            original_filename = str(original_filename)
                    else:
                        # Extract from path or URL as fallback
                        original_filename = os.path.basename(screenshot_value)
                    
                    # Fix paths to use storage directory properly
                    # First get absolute path to the image
                    if is_running_in_cloud():
                        # In cloud, construct GCS URL or use bucket path
                        storage_path = f"/storage/{screenshot_value}"
                    else:
                        # In local dev, use path relative to the storage root
                        storage_root = os.environ.get('STORAGE_PATH', os.path.join(os.path.dirname(os.path.dirname(__file__)), 'storage'))
                        storage_path = os.path.join(storage_root, screenshot_value)
                        # Make sure path exists
                        if not os.path.exists(storage_path):
                            logger.warning(f"Image path not found: {storage_path}, trying relative path")
                            storage_path = screenshot_value
                    
                    # Use a web-accessible path for the image in the report
                    web_path = f"/screenshots/{os.path.basename(screenshot_value)}"
                    
                    md += f"**Screenshot**:\n\n"
                    md += f"![{original_filename}]({web_path})\n\n"
                except Exception as e:
                    logger.error(f"Error adding screenshot to report: {str(e)}")
                    md += f"**Screenshot**: Error including screenshot: {str(e)}\n\n"
            
            # Add LLM summary if available
            if 'llm_summary' in result:
                summary_value = result.get('llm_summary')
                if not isinstance(summary_value, str):
                    logger.error(f"LLM summary is not a string but {type(summary_value)}")
                    summary_value = str(summary_value)
                md += f"**AI Summary**:\n\n"
                md += f"{summary_value}\n\n"
            
            # Add LLM error if there was an issue with AI processing
            if 'llm_error' in result:
                error_value = result.get('llm_error')
                if not isinstance(error_value, str):
                    error_value = str(error_value)
                md += f"**AI Processing Error**:\n\n"
                md += f"```\n{error_value}\n```\n\n"
            
            # Use the enhanced markdown content if available
            if 'fit_markdown_content' in result and result.get('fit_markdown_content'):
                content = result.get('fit_markdown_content')
                if not isinstance(content, str):
                    logger.error(f"fit_markdown_content is not a string but {type(content)}")
                    content = str(content)
                md += f"**Content (Enhanced Markdown)**:\n\n"
                md += f"{content}\n\n"
            elif 'markdown_content' in result and result.get('markdown_content'):
                content = result.get('markdown_content')
                if not isinstance(content, str):
                    logger.error(f"markdown_content is not a string but {type(content)}")
                    content = str(content)
                md += f"**Content (Markdown)**:\n\n"
                md += f"{content}\n\n"
            # Fall back to filtered_content if markdown isn't available
            elif 'filtered_content' in result and result.get('filtered_content'):
                content = result.get('filtered_content')
                if not isinstance(content, str):
                    logger.error(f"filtered_content is not a string but {type(content)}")
                    content = str(content)
                md += f"**Content (Extracted Text)**:\n\n"
                md += f"```\n{content}\n```\n\n"
            # Fallback to extracted text as a last resort
            elif 'extracted_text' in result:
                content = result.get('extracted_text')
                if not isinstance(content, str):
                    logger.error(f"extracted_text is not a string but {type(content)}")
                    content = str(content)
                
                # Check if OCR was enabled or disabled
                ocr_status = ""
                if 'ocr_enabled' in result:
                    ocr_status = " (OCR Enabled)" if result.get('ocr_enabled') else " (OCR Disabled)"
                
                md += f"**Extracted Text{ocr_status}**:\n\n"
                md += f"```\n{content}\n```\n\n"
        
        md += "---\n\n"
    
    # Add metadata section with information about the processing
    md += f"## Metadata\n\n"
    md += f"- **Total URLs Processed**: {len(crawl_results)}\n"
    
    # Include information about the LLM provider used if available
    try:
        llm_provider = None
        for result in crawl_results:
            if isinstance(result, dict) and 'llm_provider' in result:
                llm_provider = result.get('llm_provider')
                if not isinstance(llm_provider, str):
                    llm_provider = str(llm_provider)
                break
                
        if llm_provider:
            md += f"- **AI Provider**: {llm_provider}\n"
    except Exception as e:
        logger.error(f"Error adding LLM provider to metadata: {str(e)}")
    
    md += f"- **Generated By**: Gnosis Wraith with Enhanced Markdown Conversion\n"
    
    # Normalize excessive newlines (more than 2) to a maximum of 2
    import re
    md = re.sub(r'\n{3,}', '\n\n', md)
    
    logger.info("Markdown report generation completed successfully")
    return md

def is_running_in_cloud():
    """Detect if running in Google Cloud environment."""
    return os.environ.get('RUNNING_IN_CLOUD', '').lower() == 'true'

async def save_markdown_report(title: str, crawl_results: List[Dict[str, Any]]) -> str:
    """Save a markdown report to disk and return the file path."""
    # Ensure title is a string
    if not isinstance(title, str):
        logger.error(f"Title is not a string but {type(title)}")
        title = str(title)
    
    # Ensure crawl_results is properly structured
    if not isinstance(crawl_results, list):
        logger.error(f"crawl_results is not a list but {type(crawl_results)}")
        if crawl_results is None:
            crawl_results = []
        else:
            crawl_results = [crawl_results]
    
    # Ensure each result in crawl_results is a dictionary
    for i, result in enumerate(crawl_results):
        if not isinstance(result, dict):
            logger.error(f"Result at index {i} is not a dictionary but {type(result)}")
            crawl_results[i] = {"url": f"Item {i}", "error": f"Invalid result type: {type(result)}"}
        else:
            # Ensure all values in the dictionary are of expected types
            for key, value in list(result.items()):
                # These fields should always be strings
                if key in ['filtered_content', 'extracted_text', 'markdown_content', 'fit_markdown_content', 'title', 'url']:
                    if value is not None and not isinstance(value, str):
                        logger.error(f"Key '{key}' has invalid type {type(value)} at index {i}")
                        result[key] = str(value)
    
    report_content = generate_markdown_report(title, crawl_results)

    import string
    valid_chars = string.ascii_letters + string.digits + '-_'
    safe_title = ''.join(c if c in valid_chars else '_' for c in title)
    filename = f"{safe_title}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.md"

    report_path = os.path.join(REPORTS_DIR, filename)
    
    async with aiofiles.open(report_path, 'w') as f:
        await f.write(report_content)
    
    return report_path

def generate_json_report(title: str, crawl_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Generate a JSON report from crawl results, including LLM summaries if available."""
    # Add logging for debugging
    logger.info(f"Generating JSON report with title: {title}")
    logger.info(f"Crawl results type: {type(crawl_results)}, length: {len(crawl_results)}")
    
    # Validate crawl_results
    if not isinstance(crawl_results, list):
        logger.error(f"crawl_results is not a list, but {type(crawl_results)}")
        crawl_results = [crawl_results] if crawl_results is not None else []
    
    # Create base JSON structure
    json_report = {
        "title": title,
        "generated_at": datetime.datetime.now().isoformat(),
        "pages": [],
        "metadata": {
            "total_pages": len(crawl_results),
            "generated_by": "Gnosis Wraith with JSON Conversion"
        }
    }
    
    # Check for overall summary in any of the results
    for result in crawl_results:
        if isinstance(result, dict) and 'overall_summary' in result:
            json_report["overall_summary"] = result.get('overall_summary')
            break
    
    # Add LLM provider info if available
    for result in crawl_results:
        if isinstance(result, dict) and 'llm_provider' in result:
            json_report["metadata"]["ai_provider"] = result.get('llm_provider')
            break
    
    # Process each page
    for i, result in enumerate(crawl_results, 1):
        # Skip if result is not a dictionary
        if not isinstance(result, dict):
            logger.error(f"Result at index {i-1} is not a dictionary but {type(result)}")
            continue
        
        page_data = {
            "id": i,
            "title": result.get('original_filename', result.get('title', 'Untitled'))
        }
        
        # Check if this is an uploaded file or URL
        if 'original_filename' in result:
            page_data["file"] = result.get('original_filename')
            page_data["type"] = "file"
        else:
            page_data["url"] = result.get('url', 'Unknown URL')
            page_data["type"] = "url"
            
        # Add JavaScript setting information if available
        if 'javascript_enabled' in result:
            page_data["javascript_enabled"] = result.get('javascript_enabled', False)
        
        # Add error if present
        if 'error' in result:
            page_data["error"] = result.get('error')
        else:
            # Add screenshot info
            if 'screenshot' in result:
                screenshot_value = result.get('screenshot')
                if not isinstance(screenshot_value, str):
                    screenshot_value = str(screenshot_value)
                
                # Use a web-accessible path for the image in the report
                web_path = f"/screenshots/{os.path.basename(screenshot_value)}"
                page_data["screenshot"] = web_path
            
            # Add LLM summary if available
            if 'llm_summary' in result:
                page_data["ai_summary"] = result.get('llm_summary')
            
            # Add LLM error if there was an issue with AI processing
            if 'llm_error' in result:
                page_data["ai_error"] = result.get('llm_error')
            
            # Add content info - trying different fields in order of preference
            if 'fit_markdown_content' in result and result.get('fit_markdown_content'):
                page_data["content"] = result.get('fit_markdown_content')
                page_data["content_type"] = "enhanced_markdown"
            elif 'markdown_content' in result and result.get('markdown_content'):
                page_data["content"] = result.get('markdown_content')
                page_data["content_type"] = "markdown"
            elif 'filtered_content' in result and result.get('filtered_content'):
                page_data["content"] = result.get('filtered_content')
                page_data["content_type"] = "filtered_text"
            elif 'extracted_text' in result:
                page_data["content"] = result.get('extracted_text')
                page_data["content_type"] = "raw_text"
                
                # Check if OCR was enabled
                if 'ocr_enabled' in result:
                    page_data["ocr_enabled"] = result.get('ocr_enabled')
        
        # Add the page data to the report
        json_report["pages"].append(page_data)
    
    return json_report

async def save_json_report(title: str, crawl_results: List[Dict[str, Any]]) -> str:
    """Save a JSON report to disk and return the file path."""
    # Ensure title is a string
    if not isinstance(title, str):
        logger.error(f"Title is not a string but {type(title)}")
        title = str(title)
    
    # Ensure crawl_results is properly structured
    if not isinstance(crawl_results, list):
        logger.error(f"crawl_results is not a list but {type(crawl_results)}")
        if crawl_results is None:
            crawl_results = []
        else:
            crawl_results = [crawl_results]
    
    # Generate the JSON report
    json_report = generate_json_report(title, crawl_results)

    # Create a safe filename
    import string
    valid_chars = string.ascii_letters + string.digits + '-_'
    safe_title = ''.join(c if c in valid_chars else '_' for c in title)
    filename = f"{safe_title}_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

    report_path = os.path.join(REPORTS_DIR, filename)
    
    # Save the JSON file
    async with aiofiles.open(report_path, 'w') as f:
        await f.write(json.dumps(json_report, indent=2))
    
    return report_path

async def convert_markdown_to_html(markdown_file: str) -> str:
    """Convert a markdown file to HTML with enhanced styling for AI summaries."""
    logger.info(f"Converting markdown file to HTML: {markdown_file}")
    
    # Validate input
    if not isinstance(markdown_file, str):
        logger.error(f"markdown_file is not a string but {type(markdown_file)}")
        markdown_file = str(markdown_file)
    
    # Create HTML filename
    html_file = f"{os.path.splitext(markdown_file)[0]}.html"
    logger.info(f"HTML output will be: {html_file}")
    
    try:
        # Read markdown content
        async with aiofiles.open(markdown_file, 'r', encoding='utf-8') as f:
            md_content = await f.read()
            logger.info(f"Read {len(md_content)} bytes from markdown file")
        
        # Check for image references and make sure they're valid
        import re
        image_refs = re.findall(r'!\[(.*?)\]\((.*?)\)', md_content)
        logger.info(f"Found {len(image_refs)} image references in markdown")
        
        for alt_text, image_path in image_refs:
            logger.info(f"Found image reference in markdown: {alt_text} at path {image_path}")
            
            # Don't check paths that start with / as they're web paths
            if not image_path.startswith('/'):
                # Check if the image path exists or needs fixing
                if not os.path.isabs(image_path):
                    # Try to resolve relative to the REPORTS_DIR
                    potential_path = os.path.join(os.path.dirname(markdown_file), image_path)
                    if os.path.exists(potential_path):
                        logger.info(f"Image path is valid: {potential_path}")
                    else:
                        logger.warning(f"Image path may be invalid: {potential_path}")
        
        # Add extensions for better markdown rendering
        logger.info("Converting markdown to HTML with extensions")
        try:
            html = markdown.markdown(md_content, extensions=['tables', 'fenced_code', 'codehilite'])
            logger.info(f"Converted to HTML, size: {len(html)} bytes")
        except Exception as md_error:
            logger.error(f"Error converting markdown to HTML: {str(md_error)}")
            html = f"<p>Error converting markdown to HTML: {str(md_error)}</p><pre>{md_content}</pre>"
    except Exception as read_error:
        logger.error(f"Error reading markdown file: {str(read_error)}")
        return markdown_file

    try:
        # Create styled HTML document with the converted content
        try:
            title = os.path.basename(markdown_file)
            styled_html = f"""<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        :root {{
            --primary-color: #4e9eff;
            --bg-color: #1e2129;
            --card-bg: #282c34;
            --text-color: #e2e2e2;
            --border-color: #3a3f4b;
            --ai-summary-bg: rgba(78, 158, 255, 0.1);
            --ai-summary-border: rgba(78, 158, 255, 0.3);
        }}
        
        body {{ 
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            line-height: 1.6; 
            max-width: 900px; 
            margin: 0 auto; 
            padding: 20px;
            background-color: var(--bg-color);
            color: var(--text-color);
        }}
        
        /* Improved link styling for better visibility against dark backgrounds */
        a {{
            color: #8CB4FF; /* Lighter blue for better contrast */
            text-decoration: none;
            transition: color 0.2s ease;
        }}
        
        a:visited {{
            color: #C8A9FF; /* Lighter purple for visited links */
        }}
        
        a:hover {{
            color: #A9CBFF; /* Even lighter blue for hover state */
            text-decoration: underline;
        }}
        
        img {{ max-width: 100%; border-radius: 4px; box-shadow: 0 4px 8px rgba(0,0,0,0.3); }}
        
        code {{ 
            background-color: rgba(0,0,0,0.2); 
            padding: 2px 5px; 
            border-radius: 3px;
            text-decoration: none !important;
        }}
        
        pre {{ 
            background-color: var(--card-bg); 
            padding: 15px; 
            border-radius: 4px;
            overflow-x: auto; 
            border: 1px solid var(--border-color);
        }}
        
        /* Fix for codehilite underlines */
        .codehilite .underline, 
        .codehilite u,
        pre .underline,
        pre u,
        code .underline,
        code u {{
            text-decoration: none !important;
            border-bottom: none !important;
        }}
        
        h1, h2, h3 {{ color: var(--primary-color); }}
        
        h2 {{ 
            border-bottom: 1px solid var(--border-color);
            padding-bottom: 10px;
        }}
        
        /* Style AI summary sections */
        h3:contains('AI Summary') + p {{
            background-color: var(--ai-summary-bg);
            border: 1px solid var(--ai-summary-border);
            border-radius: 4px;
            padding: 15px;
            margin-top: 5px;
        }}
        
        hr {{
            border: none;
            border-top: 1px solid var(--border-color);
            margin: 30px 0;
        }}
    </style>
</head>
<body>
    {html}
</body>
</html>"""
            logger.info("Created styled HTML document")
        except Exception as style_error:
            logger.error(f"Error creating styled HTML: {str(style_error)}")
            styled_html = f"<html><body><h1>Error Creating Styled HTML</h1><p>{str(style_error)}</p><div>{html}</div></body></html>"
        
        # Write HTML to file
        async with aiofiles.open(html_file, 'w', encoding='utf-8') as f:
            await f.write(styled_html)
            logger.info(f"HTML file written to {html_file}")
        
        return html_file
    except Exception as e:
        logger.error(f"Error in HTML conversion: {str(e)}")
        # Create a minimal error HTML file so we still have something to return
        error_html_path = f"{os.path.splitext(markdown_file)[0]}_error.html"
        try:
            with open(error_html_path, 'w') as f:
                f.write(f"<html><body><h1>Error Converting to HTML</h1><p>{str(e)}</p></body></html>")
            return error_html_path
        except Exception:
            logger.error(f"Could not even create error HTML")
            return markdown_file  # Return original markdown file as fallback